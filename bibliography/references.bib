@inproceedings{example,
	title={{Example}},
	author={Author D},
	booktitle={Conference},
	year={2021},
	organization={IEEE}
}

@online{linGraphenhancedLargeLanguage2024,
	title = {Graph-Enhanced {{Large Language Models}} in {{Asynchronous Plan Reasoning}}},
	author = {Lin, Fangru and La Malfa, Emanuele and Hofmann, Valentin and Yang, Elle Michelle and Cohn, Anthony and Pierrehumbert, Janet B.},
	date = {2024-02-05},
	url = {https://arxiv.org/abs/2402.02805v2},
	urldate = {2024-08-22},
	abstract = {Planning is a fundamental property of human intelligence. Reasoning about asynchronous plans is challenging since it requires sequential and parallel planning to optimize time costs. Can large language models (LLMs) succeed at this task? Here, we present the first large-scale study investigating this question. We find that a representative set of closed and open-source LLMs, including GPT-4 and LLaMA-2, behave poorly when not supplied with illustrations about the task-solving process in our benchmark AsyncHow. We propose a novel technique called Plan Like a Graph (PLaG) that combines graphs with natural language prompts and achieves state-of-the-art results. We show that although PLaG can boost model performance, LLMs still suffer from drastic degradation when task complexity increases, highlighting the limits of utilizing LLMs for simulating digital devices. We see our study as an exciting step towards using LLMs as efficient autonomous agents. Our code and data are available at https://github.com/fangru-lin/graph-llm-asynchow-plan.},
	langid = {english},
	organization = {arXiv.org},
	file = {/home/mick/Zotero/storage/EB8C7R9B/Lin et al. - 2024 - Graph-enhanced Large Language Models in Asynchronous Plan Reasoning.pdf}
}

@online{yangBufferThoughtsThoughtAugmented2024,
	title = {Buffer of {{Thoughts}}: {{Thought-Augmented Reasoning}} with {{Large Language Models}}},
	shorttitle = {Buffer of {{Thoughts}}},
	author = {Yang, Ling and Yu, Zhaochen and Zhang, Tianjun and Cao, Shiyi and Xu, Minkai and Zhang, Wentao and Gonzalez, Joseph E. and Cui, Bin},
	date = {2024-06-06},
	eprint = {2406.04271},
	eprinttype = {arXiv},
	eprintclass = {cs},
	doi = {10.48550/arXiv.2406.04271},
	url = {http://arxiv.org/abs/2406.04271},
	urldate = {2024-06-22},
	abstract = {We introduce Buffer of Thoughts (BoT), a novel and versatile thought-augmented reasoning approach for enhancing accuracy, efficiency and robustness of large language models (LLMs). Specifically, we propose meta-buffer to store a series of informative high-level thoughts, namely thought-template, distilled from the problem-solving processes across various tasks. Then for each problem, we retrieve a relevant thought-template and adaptively instantiate it with specific reasoning structures to conduct efficient reasoning. To guarantee the scalability and stability, we further propose buffer-manager to dynamically update the meta-buffer, thus enhancing the capacity of meta-buffer as more tasks are solved. We conduct extensive experiments on 10 challenging reasoning-intensive tasks, and achieve significant performance improvements over previous SOTA methods: 11\% on Game of 24, 20\% on Geometric Shapes and 51\% on Checkmate-in-One. Further analysis demonstrate the superior generalization ability and model robustness of our BoT, while requiring only 12\% of the cost of multi-query prompting methods (e.g., tree/graph of thoughts) on average. Notably, we find that our Llama3-8B+BoT has the potential to surpass Llama3-70B model. Our project is available at: https://github.com/YangLing0818/buffer-of-thought-llm},
	pubstate = {prepublished},
	version = {1},
	keywords = {Computer Science - Computation and Language},
	file = {/home/mick/Zotero/storage/RCLB4VMH/Yang et al. - 2024 - Buffer of Thoughts Thought-Augmented Reasoning wi.pdf;/home/mick/Zotero/storage/6BMPGT72/2406.html}
}
